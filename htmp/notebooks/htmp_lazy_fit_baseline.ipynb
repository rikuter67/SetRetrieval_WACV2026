{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hull Tactical Market Prediction – Lazy-Fit Streaming Baseline\n",
        "\n",
        "Kaggleの評価API(DefaultInferenceServer)にそのまま投げられるようにしたノートブックのスターターです。初回の予測時に train.csv を動的に学習し、以降は受け取ったバッチに対して 1 つの数値を返します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Optional: install extra packages\n",
        "\n",
        "Kaggle Notebook には numpy/pandas/scikit-learn/polars が同棒機ですが、反復用中には下記を差し込んで使用してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Kaggle の Python インスタンスでは必要ない場合がほとんどです。\n",
        "# 必要ならコメントアウトを外してください。\n",
        "# !pip install polars --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ライブラリの読み込みとユーティリティ\n",
        "\n",
        "下記は Kaggle で提供される DefaultInferenceServer 用のベースラインコードです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline"
      },
      "outputs": [],
      "source": [
        "# === Hull Tactical - Market Prediction: lazy-fit baseline for evaluation API ===\n",
        "#  - 初回 predict 呼び出し時に train.csv を読み込んで学習（Ridge回帰 + 標準化 + 欠損中央値補完）\n",
        "#  - 以降は受け取ったバッチ（1タイムステップ想定）に対して予測スカラを返す\n",
        "#  - 数値列のみを特徴量として自動選択（ID/日付/目的変数は除外）\n",
        "#\n",
        "# 返り値仕様：\n",
        "#   - スカラ float を返す（タイムステップ1つにつき1値の予測）\n",
        "#   - 万一、評価側が複数行を1度に渡す場合は、行ごとの予測を平均してスカラに畳み返却\n",
        "#\n",
        "# 依存：\n",
        "#   - scikit-learn が利用可能な環境を想定（不可なら numpy 最小自前実装にフォールバック）\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Iterable, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import polars as pl\n",
        "except Exception:\n",
        "    pl = None\n",
        "\n",
        "try:\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    _HAS_SK = True\n",
        "except Exception:\n",
        "    Ridge = StandardScaler = None\n",
        "    _HAS_SK = False\n",
        "\n",
        "from kaggle_evaluation.default_inference_server import DefaultInferenceServer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "TARGET = os.getenv(\"HTMP_TARGET\", \"forward_returns\")\n",
        "ID_CANDIDATES = {\"row_id\", \"id\", \"ID\"}\n",
        "DATE_CANDIDATES = {\"date\", \"timestamp\", \"time\", \"Date\"}\n",
        "DATA_ROOTS = (\n",
        "    \"/kaggle/input/hull-tactical-market-prediction\",\n",
        "    \"/kaggle/input/hull-tactical-market-prediction/\",\n",
        "    \"../input/hull-tactical-market-prediction\",\n",
        "    \"../input/hull-tactical-market-prediction/\",\n",
        "    \"data/raw\",\n",
        "    \"./\",\n",
        ")\n",
        "\n",
        "\n",
        "@dataclass(slots=True)\n",
        "class ModelArtifacts:\n",
        "    feature_columns: list[str]\n",
        "    medians: dict[str, float]\n",
        "    scaler: Optional[StandardScaler]\n",
        "    model: object\n",
        "\n",
        "\n",
        "def resolve_path(fname: str) -> Optional[str]:\n",
        "    for root in DATA_ROOTS:\n",
        "        candidate = os.path.join(root, fname)\n",
        "        if os.path.exists(candidate):\n",
        "            return candidate\n",
        "    if os.path.exists(fname):\n",
        "        return fname\n",
        "    return None\n",
        "\n",
        "\n",
        "def read_csv(path: str) -> pd.DataFrame:\n",
        "    if pl is not None:\n",
        "        return pl.read_csv(path).to_pandas()\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "\n",
        "def infer_numeric_columns(df: pd.DataFrame) -> list[str]:\n",
        "    exclude = set()\n",
        "    exclude.update(col for col in df.columns if col in ID_CANDIDATES)\n",
        "    exclude.update(col for col in df.columns if col in DATE_CANDIDATES)\n",
        "    if TARGET in df.columns:\n",
        "        exclude.add(TARGET)\n",
        "    numeric_cols = [\n",
        "        col for col in df.columns if col not in exclude and pd.api.types.is_numeric_dtype(df[col])\n",
        "    ]\n",
        "    return numeric_cols\n",
        "\n",
        "\n",
        "def median_impute(df: pd.DataFrame, medians: dict[str, float]) -> pd.DataFrame:\n",
        "    for col, value in medians.items():\n",
        "        df[col] = df[col].fillna(value)\n",
        "    return df\n",
        "\n",
        "\n",
        "def fit_manual_ridge(X: np.ndarray, y: np.ndarray, lam: float = 1.0):\n",
        "    mu = X.mean(axis=0)\n",
        "    std = X.std(axis=0) + 1e-8\n",
        "    Xs = (X - mu) / std\n",
        "    a = Xs.T @ Xs + lam * np.eye(Xs.shape[1])\n",
        "    b = Xs.T @ y\n",
        "    weights = np.linalg.solve(a, b)\n",
        "    bias = float(y.mean() - (mu / std) @ weights)\n",
        "    return weights, bias, mu, std\n",
        "\n",
        "\n",
        "class LazyBaseline:\n",
        "    def __init__(self) -> None:\n",
        "        self.artifacts: Optional[ModelArtifacts] = None\n",
        "\n",
        "    def _fit(self) -> None:\n",
        "        train_path = resolve_path(\"train.csv\")\n",
        "        if train_path is None:\n",
        "            raise FileNotFoundError(\"train.csv が見つかりません。DATA_ROOTS を確認してください。\")\n",
        "\n",
        "        train_df = read_csv(train_path)\n",
        "        if TARGET not in train_df.columns:\n",
        "            raise KeyError(\n",
        "                f\"目的変数カラム '{TARGET}' が train.csv に見つかりません。\"\n",
        "            )\n",
        "\n",
        "        numeric_cols = infer_numeric_columns(train_df)\n",
        "        features = train_df[numeric_cols].copy()\n",
        "        y = train_df[TARGET].astype(float).values\n",
        "\n",
        "        medians = {\n",
        "            col: (features[col].median() if pd.api.types.is_numeric_dtype(features[col]) else 0.0)\n",
        "            for col in numeric_cols\n",
        "        }\n",
        "        features = median_impute(features, medians)\n",
        "\n",
        "        if _HAS_SK:\n",
        "            scaler = StandardScaler()\n",
        "            Xs = scaler.fit_transform(features.values)\n",
        "            model = Ridge(alpha=1.0, random_state=42)\n",
        "            model.fit(Xs, y)\n",
        "        else:\n",
        "            scaler = None\n",
        "            model = fit_manual_ridge(features.values, y)\n",
        "\n",
        "        self.artifacts = ModelArtifacts(\n",
        "            feature_columns=numeric_cols,\n",
        "            medians=medians,\n",
        "            scaler=scaler,\n",
        "            model=model,\n",
        "        )\n",
        "\n",
        "    def _ensure_fitted(self) -> ModelArtifacts:\n",
        "        if self.artifacts is None:\n",
        "            self._fit()\n",
        "        assert self.artifacts is not None\n",
        "        return self.artifacts\n",
        "\n",
        "    def _prepare_features(self, batch: pd.DataFrame, artifacts: ModelArtifacts) -> pd.DataFrame:\n",
        "        aligned = pd.DataFrame(index=batch.index)\n",
        "        for col in artifacts.feature_columns:\n",
        "            if col in batch.columns and pd.api.types.is_numeric_dtype(batch[col]):\n",
        "                aligned[col] = batch[col]\n",
        "            else:\n",
        "                aligned[col] = np.nan\n",
        "        aligned = median_impute(aligned, artifacts.medians.copy())\n",
        "        return aligned\n",
        "\n",
        "    def predict(self, batch) -> float:\n",
        "        artifacts = self._ensure_fitted()\n",
        "\n",
        "        if isinstance(batch, pl.DataFrame):\n",
        "            frame = batch.to_pandas()\n",
        "        elif isinstance(batch, pd.DataFrame):\n",
        "            frame = batch\n",
        "        else:\n",
        "            frame = pd.DataFrame(batch)\n",
        "\n",
        "        features = self._prepare_features(frame, artifacts)\n",
        "        values = features.values\n",
        "\n",
        "        if _HAS_SK and artifacts.scaler is not None:\n",
        "            scaled = artifacts.scaler.transform(values)\n",
        "            preds = artifacts.model.predict(scaled)\n",
        "        else:\n",
        "            weights, bias, mu, std = artifacts.model\n",
        "            scaled = (values - mu) / std\n",
        "            preds = scaled @ weights + bias\n",
        "\n",
        "        return float(np.mean(preds))\n",
        "\n",
        "\n",
        "BASELINE = LazyBaseline()\n",
        "\n",
        "\n",
        "def predict(batch) -> float:\n",
        "    return BASELINE.predict(batch)\n",
        "\n",
        "\n",
        "server = DefaultInferenceServer(predict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ローカル実行 or コンペ提出\n",
        "\n",
        "Kaggle 環境で `KAGGLE_IS_COMPETITION_RERUN` が設定されていれば `server.serve()` が呼ばれます。\n",
        "Notebook ではローカルゲートウェイでテスト可能です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gateway"
      },
      "outputs": [],
      "source": [
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    server.serve()\n",
        "else:\n",
        "    # Notebook 上ではローカルゲートウェイに接続して動作確認できます。\n",
        "    server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}